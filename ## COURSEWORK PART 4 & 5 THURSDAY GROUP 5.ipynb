{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec0d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= pd.read_csv(r'C:\\Users\\Avishkar\\OneDrive\\Documents\\hw dataset\\x_train_all.csv')\n",
    "y= pd.read_csv(r'C:\\Users\\Avishkar\\OneDrive\\Documents\\hw dataset\\y_train_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9defe99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eaecd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275846d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5c302fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(classifier, X_train, y_train, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44ab573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Cross-Validation Accuracy: 0.9291237113402062\n",
      "Fold 2 Cross-Validation Accuracy: 0.9239690721649485\n",
      "Fold 3 Cross-Validation Accuracy: 0.9303225806451613\n",
      "Fold 4 Cross-Validation Accuracy: 0.9148387096774193\n",
      "Fold 5 Cross-Validation Accuracy: 0.9212903225806451\n",
      "Fold 6 Cross-Validation Accuracy: 0.9509677419354838\n",
      "Fold 7 Cross-Validation Accuracy: 0.9393548387096774\n",
      "Fold 8 Cross-Validation Accuracy: 0.9161290322580645\n",
      "Fold 9 Cross-Validation Accuracy: 0.9251612903225807\n",
      "Fold 10 Cross-Validation Accuracy: 0.9148387096774193\n"
     ]
    }
   ],
   "source": [
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f'Fold {i} Cross-Validation Accuracy: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84b999cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validation Accuracy: 0.9265996009311606\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Cross-Validation Accuracy: {np.mean(cv_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b447200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf0616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f992be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acf30200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9293085655314758\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba634ca7",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f1f44",
   "metadata": {},
   "source": [
    "#### VARIOUS PARAMETERS OF NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d0d0278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    \"activation_functions\": ['logistic', 'tanh', 'relu'],\n",
    "    \"max_epochs\": [50, 100, 200],\n",
    "    \"validation_thresholds\": [0.1, 0.01, 0.001],\n",
    "    \"momentum_values\": [0.9, 0.7, 0.5],\n",
    "    \"hidden_layer_sizes_list\": [(100,), (50, 50), (100, 50, 25)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "990c1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bf33d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_layer_sizes in params[\"hidden_layer_sizes_list\"]:\n",
    "    for activation in params[\"activation_functions\"]:\n",
    "        for learning_rate in params[\"learning_rate\"]:\n",
    "            for momentum in params[\"momentum_values\"]:\n",
    "                for max_epoch in params[\"max_epochs\"]:\n",
    "                    for validation_threshold in params[\"validation_thresholds\"]:\n",
    "                        classifier = MLPClassifier(\n",
    "                            hidden_layer_sizes=hidden_layer_sizes,\n",
    "                            activation=activation,\n",
    "                            learning_rate_init=learning_rate,\n",
    "                            momentum=momentum,\n",
    "                            max_iter=max_epoch,\n",
    "                            validation_fraction=validation_threshold,\n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ff57335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Hidden Layer Sizes=(100, 50, 25), Activation=relu, Learning Rate=0.3, Momentum=0.5, Epochs=200, Validation Threshold=0.001\n"
     ]
    }
   ],
   "source": [
    "print(f'Parameters: Hidden Layer Sizes={hidden_layer_sizes}, Activation={activation}, '\n",
    "                              f'Learning Rate={learning_rate}, Momentum={momentum}, Epochs={max_epoch}, '\n",
    "                              f'Validation Threshold={validation_threshold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d644105",
   "metadata": {},
   "source": [
    "#### shaping the numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "179256de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ed540bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = x_array.reshape(-1, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9278d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height, image_width, num_channels = x_reshaped.shape[1], x_reshaped.shape[2], x_reshaped.shape[3]\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "y_one_hot = tf.keras.utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7223df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_reshaped, y_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963b28a",
   "metadata": {},
   "source": [
    "#### hyperparameters for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71f32a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'filters': [32, 64],\n",
    "    'kernel_size': [(3, 3), (5, 5)],\n",
    "    'pool_size': [(2, 2), (3, 3)],\n",
    "    'dense_neurons': [128, 256],\n",
    "    'dropout_rate': [0.25, 0.5],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ad92b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e3498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=32, Epochs=10\n",
      "Test Accuracy: 0.8787409663200378\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=32, Epochs=20\n",
      "Test Accuracy: 0.7770897746086121\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=64, Epochs=10\n",
      "Test Accuracy: 0.8276574015617371\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=64, Epochs=20\n",
      "Test Accuracy: 0.7858617305755615\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.01, Batch Size=32, Epochs=10\n",
      "Test Accuracy: 0.23581011593341827\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.01, Batch Size=32, Epochs=20\n",
      "Test Accuracy: 0.23581011593341827\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.01, Batch Size=64, Epochs=10\n",
      "Test Accuracy: 0.7997936010360718\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.25, Learning Rate=0.01, Batch Size=64, Epochs=20\n",
      "Test Accuracy: 0.23581011593341827\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.001, Batch Size=32, Epochs=10\n",
      "Test Accuracy: 0.7610939145088196\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.001, Batch Size=32, Epochs=20\n",
      "Test Accuracy: 0.7719298005104065\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.001, Batch Size=64, Epochs=10\n",
      "Test Accuracy: 0.7879257202148438\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.001, Batch Size=64, Epochs=20\n",
      "Test Accuracy: 0.7585139274597168\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.01, Batch Size=32, Epochs=10\n",
      "Test Accuracy: 0.7409700751304626\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.01, Batch Size=32, Epochs=20\n",
      "Test Accuracy: 0.7915376424789429\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.01, Batch Size=64, Epochs=10\n",
      "Test Accuracy: 0.7368420958518982\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=128, Dropout Rate=0.5, Learning Rate=0.01, Batch Size=64, Epochs=20\n",
      "Test Accuracy: 0.7966976165771484\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=256, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=32, Epochs=10\n",
      "Test Accuracy: 0.8436532616615295\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=256, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=32, Epochs=20\n",
      "Test Accuracy: 0.789989709854126\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=256, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=64, Epochs=10\n",
      "Test Accuracy: 0.8405572772026062\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=256, Dropout Rate=0.25, Learning Rate=0.001, Batch Size=64, Epochs=20\n",
      "Test Accuracy: 0.8400412797927856\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=256, Dropout Rate=0.25, Learning Rate=0.01, Batch Size=32, Epochs=10\n",
      "Test Accuracy: 0.7992776036262512\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=256, Dropout Rate=0.25, Learning Rate=0.01, Batch Size=32, Epochs=20\n",
      "Test Accuracy: 0.23632611334323883\n",
      "\n",
      "Parameters: Filters=32, Kernel Size=(3, 3), Pool Size=(2, 2), Dense Neurons=256, Dropout Rate=0.25, Learning Rate=0.01, Batch Size=64, Epochs=10\n",
      "Test Accuracy: 0.8446852564811707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filters in param_grid['filters']:\n",
    "    for kernel_size in param_grid['kernel_size']:\n",
    "        for pool_size in param_grid['pool_size']:\n",
    "            for dense_neurons in param_grid['dense_neurons']:\n",
    "                for dropout_rate in param_grid['dropout_rate']:\n",
    "                    for learning_rate in param_grid['learning_rate']:\n",
    "                        for batch_size in param_grid['batch_size']:\n",
    "                            for epochs in param_grid['epochs']:\n",
    "                           \n",
    "                                model = Sequential()\n",
    "                                model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=(image_height, image_width, num_channels)))\n",
    "                                model.add(MaxPooling2D(pool_size=pool_size))\n",
    "                                model.add(Flatten())\n",
    "                                model.add(Dense(dense_neurons, activation='relu'))\n",
    "                                model.add(Dropout(dropout_rate))\n",
    "                                model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "                                \n",
    "                                optimizer = Adam(learning_rate=learning_rate)\n",
    "                                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                            \n",
    "                                datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "                                train_generator = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "\n",
    "                    \n",
    "                                model.fit(train_generator, epochs=epochs, validation_data=(X_test, y_test), batch_size=batch_size, verbose=0)\n",
    "\n",
    "                           \n",
    "                                _, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "                              \n",
    "                                print(f'Parameters: Filters={filters}, Kernel Size={kernel_size}, Pool Size={pool_size}, Dense Neurons={dense_neurons}, Dropout Rate={dropout_rate}, Learning Rate={learning_rate}, Batch Size={batch_size}, Epochs={epochs}')\n",
    "                                print(f'Test Accuracy: {test_accuracy}\\n')\n",
    "\n",
    "                                \n",
    "                                if test_accuracy > best_accuracy:\n",
    "                                    best_accuracy = test_accuracy\n",
    "                                    best_params = {\n",
    "                                        'filters': filters,\n",
    "                                        'kernel_size': kernel_size,\n",
    "                                        'pool_size': pool_size,\n",
    "                                        'dense_neurons': dense_neurons,\n",
    "                                        'dropout_rate': dropout_rate,\n",
    "                                        'learning_rate': learning_rate,\n",
    "                                        'batch_size': batch_size,\n",
    "                                        'epochs': epochs\n",
    "                                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a38a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
